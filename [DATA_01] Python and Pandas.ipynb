{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMrM0upOdLB/FSRuK7LbTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikecinnamon/MLearning/blob/main/%5BDATA_01%5D%20Python%20and%20Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [DATA-01] Python and Pandas"
      ],
      "metadata": {
        "id": "6Z9XysR_2gnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Python?"
      ],
      "metadata": {
        "id": "J2DYQMpn2nte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Python** is a programming language, born in 1991. The latest stable version (when this is being written) is Python 3.14. As a programming language, Python can be used by a programmer to write a program that performs a task. Since this course is data-oriented, let us mention a few examples in that line:\n",
        "\n",
        "* A **web scraping** program that captures data on the current prices published in an e-commerce web site, storing them in a database.\n",
        "\n",
        "* A **machine learning** program that trains an algorithm that assigns credit scores to borrowers in a lending platform.\n",
        "\n",
        "* A **pricing algorithm** that estimates the market price of a real estate asset.\n",
        "\n",
        "These programs are later executed many times without being modified. But you can use Python in other ways. For instance, to examine the variation of the stock price of a specific company, or the structure of the vacation rental market in a specific region. Either for developing a program, which always involves a bit of trial and error, or in a data analysis, we use a basic tool, the **Python interactive interpreter**. We can have several instances of the interpreter, called **kernels**, running independently in our computer. To deal with the Python interpreter, Pythonistas use an app that provides an as interface to the Python interpreter, chosen among the many available choices (see below)."
      ],
      "metadata": {
        "id": "3YiKes8e2tzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python modules and packages"
      ],
      "metadata": {
        "id": "9Pc_FzpN2x6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many additional resources have been added to Python in the form of **modules**. A module is just a text file containing Python code. Modules are grouped in **libraries**. The **Python Standard Library**, distributed with Python, contains **built-in modules** providing standardized solutions for many problems that occur in everyday programming. For instance, the module `math` provides mathematical functions, while the module `datetime` provides functions for manipulating dates and times.\n",
        "\n",
        "Other libraries are typically called **packages**, because their elements are packed according to some specific rules which allow you to install and call them together. Python can be extended by more than 300,000 packages. Some big packages like scikit-learn (a machine learning toolkit) have **subpackages**.\n",
        "\n",
        "Since the basic Python toolkit (without any module) is quite limited, you will need to **import** additional resources for practically everything. Once a module has been imported, all its functions are available. Alternatively, you can import a single function from a module. Resources are imported just for the current kernel. You can only import from packages which are already **installed** in your computer.\n",
        "\n",
        "Almost everything in the Python world is open-source. In particular, Python packages are contributed by various agents, such as university professors, freelance programmers, or industry behemoths like Google. This leads to a dynamic ecosystem, where you may find overlapping, dependencies and multiple versions."
      ],
      "metadata": {
        "id": "7VjG7eZW29ND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python distributions"
      ],
      "metadata": {
        "id": "tw2vD3Ad3AuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **Python distribution** is a software bundle, containing, at least, a Python interpreter and the corresponding version of the standard library. It also includes a collection of packages and one or more package managers for installing, uninstalling or updating packages. All distributions have a **package manager** called `pip`, and some distributions have a specific package manager.\n",
        "\n",
        "One option for working with Python is to start a Python kernel directly in a **shell** application associated to the operating system of your computer. Shell apps are typically called **Terminal** in Mac/Linux computers and **Prompt** in Windows computers. For this approach to work, the shell app has to find the Python files. This is automatic when the folder where the Python distribution is in the **path** of that shell. In the contrary, you have to know where to find it.\n",
        "\n",
        "If you are just starting with Python, you will prefer a friendlier approach. Python distributions provide various interfaces to the Python interpreter. All include a **command line interface** (CLI), which may be a shell-like application or an **integrated development environment** (IDE). A Python IDE provides a Python-aware code editor integrated with the ability to run code from that editor. Details about one of the top popular Python distributions follow."
      ],
      "metadata": {
        "id": "BZJ48ml13KJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Anaconda distribution"
      ],
      "metadata": {
        "id": "yrcQM-BO3Mx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the data science community, **Anaconda** (`anaconda.com`) is the favorite distribution. The current Anaconda distribution comes with Python 3.10. Anaconda provides all the packages used in this course, so no extra installation is needed. Anyway, Anaconda has a specific package manager, called `conda`. You may need `conda` for more advanced work, because it reviews the packages that are already installed in our computer, keeping track of the dependencies, and solving version conflicts between packages. On the downside, `conda` is much slower than `pip`.\n",
        "\n",
        "After downloading and installing Anaconda, you can start your Python experience with the **Anaconda Navigator**, which opens in the browser and allows you to choose among different interfaces to the Python interpreter. First, you have **Jupyter Qt Console**, which is a shell-like app with some extra features. Jupyter (Julia/Python/R) is a new name for an older project called **IPython** (Interactive Python). IPython's contribution was the IPython shell, which added some features to the mere Python language. Qt Console is the result of adding a **graphical user interface** (GUI), with drop-down menus, mouse-clicking, etc, to the IPython shell, by means of a toolkit called Qt.\n",
        "\n",
        "Part of the popularity of the IPython shell was due to the **magic commands**, which were extra commands written as `%cmd`. For instance, `%cd` allows you to change the **working directory**. These commands *are not part of Python*. Though some textbooks and tutorials are still very keen on magic commands, these commands appear very briefly in this course. To get more information about them, enter `%quickref` in the console. Although, in practice, you can omit the percentage sign (so `%cd` works exactly the same as `cd`), it is always safer to keep using it to distinguish the magic commands from the Python code.\n",
        "\n",
        "Jupyter provides an alternative approach, based on the **notebook** concept. A notebook is kind of document where you can combine input, output and ordinary text. A notebook is stored in a file with extension `ipynb` (IPython notebook). In the notebook arena, **Jupyter Notebook** is the leading choice. Notebooks are multilingual, that is, they can be used, not only with Python, but also with other languages like R. Most data scientists prefer the console for developing their code, but use notebooks for diffusion, specially for posting their work on platforms like **GitHub**.\n",
        "\n",
        "Besides the Jupyter apps, Anaconda also provides a Python IDE called **Spyder**, where you can manage together a console and a text editor for your code. If you have previous experience with IDE's, for instance from working with R in RStudio, you may prefer Spyder to Qt Console.\n",
        "\n",
        "Once Anaconda is installed, you can bypass the navigator by calling your preferred interface from a shell. To start Qt Console, enter `jupyter qtconsole`. To get access to the notebooks in the default browser (*e.g*. Google Chrome), enter `jupyter notebook`. To start Spyder, enter `spyder`.\n",
        "\n",
        "*Note*. Use *Anaconda Prompt* in Windows, instead of the standard Windows prompt, whose path does not contain the Anaconda apps."
      ],
      "metadata": {
        "id": "a8AKpFJ43QVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The main packages"
      ],
      "metadata": {
        "id": "vyk8wflj3U-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This course does not look at Python as a programming language, but from a very specific perspective, assuming a data science context. From this perspective, the main Python packages are:\n",
        "\n",
        "* **NumPy** adds support for large vectors and matrices, called there **arrays**.\n",
        "\n",
        "* **Matplotlib**, based on NumPy, provides a plotting toolkit.\n",
        "\n",
        "* **Pandas** is a popular library for data management, used in the examples of this course. Pandas is built on top of NumPy and Matplotlib."
      ],
      "metadata": {
        "id": "fzubvrUG3qwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab notebooks"
      ],
      "metadata": {
        "id": "Og-Q6Qvi3u16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Google Colaboratory** is a Google app which allows you to write and executing Python code in a browser, with some advantages: (a) it does not require installation nor configuration, (b) it gives you access to GPU's (meaning more computing power) for free, and (c) it allows you an easy way to share content. In Google Colaboratory, you work with documents called **Colab notebooks**. Though they are not exactly the same, Colab notebooks are pretty similar to Jupyter notebooks, and they stored in Google Drive as files with extension `ipynb`.\n",
        "\n",
        "You may be interested in using Colab, since you can access it from any deviced connected to Internet, such as an IPAD. The only thing you need to start working with Colab notebooks is a Google account, meaning a `gmail.com` address and its password. Colab work happens in **Google Drive** (enter through `https://www.google.com/drive`). In your debout, you have to install the Google Colaboratory app in your drive. To do this, click on the *Settings* button, select *Settings >> Manage apps* button and click on *Connect more apps*. `ipynb` files can be uploaded to and downloaded from Google Drive."
      ],
      "metadata": {
        "id": "sSfEr_Dc3xBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Typing Python code"
      ],
      "metadata": {
        "id": "WNiAMRU-30si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us assume that you are working on Jupyter Qt Console. The console produces **input prompts** (such as `In[1]:`), where you can type a command and press *Return*. The console responds with either the corresponding **output** (preceded by `Out[1]:`), an **error message** or no answer at all. Error messages are typically long and unfriendly.\n",
        "\n",
        "A simple example follows. Note the white space in the input, around the *plus* sign (`+`), which is ignored by the Python interpreter, but improves the **readability** of our code."
      ],
      "metadata": {
        "id": "x34e2wxv7v_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "2 + 2"
      ],
      "metadata": {
        "id": "gnKYxHEX7zIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, if you enter `2 + 2`, the output will be the result of this calculation. But, if you want to store this result for later use (in the same session), you will enter it with a name, as follows:"
      ],
      "metadata": {
        "id": "ZO20zEeU71gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2 + 2"
      ],
      "metadata": {
        "id": "xr_Zj72D75T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates the **variable** `a`. Note that the value of `2 + 2` is not outputted now. But you can call it:"
      ],
      "metadata": {
        "id": "J_oHtLsb77VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "vN423rLt797a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Pyhton, when you assign a value to a variable which has already been created, the previous assignment is forgotten:"
      ],
      "metadata": {
        "id": "lm1KTg0f7_Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 7 - 2"
      ],
      "metadata": {
        "id": "g7XTiquP8CLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "iv7OTStd8D_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose that you copypaste in the console code chunks from a text editor. This is what you would do if you were working in the console, so you could readily save your code. You can so input several code lines at once. In that case, the console only shows the output for the last line of the input. An example follows."
      ],
      "metadata": {
        "id": "qrV1bkL-8Gfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = 2 * 3\n",
        "b - 1\n",
        "b**2"
      ],
      "metadata": {
        "id": "_KQWJPH58MaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note*. You would probably have written `b^2` for the square of 2, but the caret symbol (`^`) plays a different role in Python.\n",
        "\n",
        "If you are typing the code in the console, you can open a new line within the same input with *Ctrl+Return*. You can then finish the input, calling for the output, by pressing *Return*. If the cursor is not at the end of the last line, you have to press *Shift+Return* to finish the input.\n",
        "\n",
        "Typing in a notebook is just a bit different. The notebook is a sequence of **cells**. There two type of cells, the Markdown cells and the code cells. In the **Markdown cells**, you write comments, while in the **code cells** you write the Python commands. Every code cell of the notebook corresponds to an input of the console. When you are typing in a cell, pressing *Return* starts a new line *within the same cell*, without ending the input. With *Shift+Return*, you finish the the input, so you get the ouput, opening a new cell. To finish the input without opening a new cell, use *Cmd+Return* in Mac or *Ctrl+Return* in Windows."
      ],
      "metadata": {
        "id": "YQy5SnQ38QV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python packages"
      ],
      "metadata": {
        "id": "HJ5Ni4428UsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Python resources come in **packages**. For instance, suppose that you want to do some math, calculating the square root of 2. You will then **import** the package `math`, whose resources include the square root and many other mathematical functions. Once the package has been imported, all its functions are available, so you can call the function as `math.sqrt()`. This notation indicates that `sqrt()` is a function of the module `math`.\n",
        "\n",
        "So, the square root calculation shows up as:"
      ],
      "metadata": {
        "id": "rB1wcTzA8eDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "math.sqrt(2)"
      ],
      "metadata": {
        "id": "QIao8C_K8h5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can import only the functions that you plan to use:"
      ],
      "metadata": {
        "id": "gHQ5vkOc8kzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(2)"
      ],
      "metadata": {
        "id": "HZNhbPP-8t1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Packages are imported just for the current kernel. You can only import a package only if it is already **installed** in your computer. With the Anaconda distribution, all the packages used in this course are already available and can be directly imported.\n",
        "\n",
        "*Note*. This course follows the common practice in Python learning materials of writing functions as *func()*. The parentheses remind you that this is an object that takes arguments."
      ],
      "metadata": {
        "id": "LADIwU1A8xXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The main packages"
      ],
      "metadata": {
        "id": "U7206f9k80Uy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This course does not look at Python as a programming language, but from a very specific perspective. Our approach is mainly based on the **package Pandas**.\n",
        "\n",
        "In the data science context, the main Python packages are:\n",
        "\n",
        "* **NumPy** adds support for large vectors and matrices, called there **arrays**.\n",
        "\n",
        "* Based on NumPy, the library **Matplotlib** is Python's plotting workhorse.\n",
        "\n",
        "* Pandas is a popular library for data management, used in all the examples of this course. Pandas is built on top of NumPy and Matplotlib.\n",
        "\n",
        "* scikit-learn is a library of **machine learning** methods."
      ],
      "metadata": {
        "id": "wMSc0iYY82ZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numeric types"
      ],
      "metadata": {
        "id": "KCw42i2f85rC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in other languages, data can have different **data types** in Python. The data type can be learned with the function `type()`. Let me start with the numeric types. For the variable `a` defined above:"
      ],
      "metadata": {
        "id": "fn-4_Xg288-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(a)"
      ],
      "metadata": {
        "id": "XDaqEgq98_A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, `a` has type `int` (meaning integer). Another numeric type is that of **floating-point** numbers (`float`), which have decimals:"
      ],
      "metadata": {
        "id": "fhXahbpw9A_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = math.sqrt(2)\n",
        "type(b)"
      ],
      "metadata": {
        "id": "3fzLRvu-9DW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are subdivisions of these two basic types (such as `int64`), but we skip them in this brief tutorial. Note that, in Python, integers are not, as in the mathematics textbook, a subset of the real numbers, but a different type:"
      ],
      "metadata": {
        "id": "mYbZxOY89G9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(2)"
      ],
      "metadata": {
        "id": "kbTPXWPs9JQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(2.0)"
      ],
      "metadata": {
        "id": "KGhnHzHG9Lyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above square root calculation, `b` got type `float` because this is what the `math` function `sqrt()` returns. The functions `int()` and `float()` can be used to convert numbers from one type to another type (sometimes at a loss):"
      ],
      "metadata": {
        "id": "I1n1Xh6L9OU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float(2)"
      ],
      "metadata": {
        "id": "5cL7njTK9Qxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(2.3)"
      ],
      "metadata": {
        "id": "HhtGgpho9Srt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boolean data"
      ],
      "metadata": {
        "id": "VPIX54tx9Uqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also have **Boolean** (`bool`) variables, whose value is either `True` or `False`:"
      ],
      "metadata": {
        "id": "ZruvRQZM9cgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = 5 < a\n",
        "d"
      ],
      "metadata": {
        "id": "gjRVhYoi9ec8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(d)"
      ],
      "metadata": {
        "id": "Qq46BfVz9hYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even if they don't appear explicitly, Booleans may come under the hood. When you enter an expression involving a comparison such as `5 < a`, the Python interpreter evaluates it, returning either `True` or `False`.  Here, we have defined a variable by means of such an expression, so we got a Boolean variable. Warning: as a comparison operator, equality is denoted by two equal signs. This may surprise you."
      ],
      "metadata": {
        "id": "xX3MSrPY9jfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a == 4"
      ],
      "metadata": {
        "id": "nWSSSht_9l-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boolean variables can be converted to `int` and `float` type by the functions mentioned above, but also by a mathematical operator:"
      ],
      "metadata": {
        "id": "q10v3xKA9nve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "math.sqrt(d)"
      ],
      "metadata": {
        "id": "C4tfTfuq9qXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1 - d"
      ],
      "metadata": {
        "id": "rzPU-dCS9sSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Strings"
      ],
      "metadata": {
        "id": "SnCDKXnI9uO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides numbers, we can also manage **strings** with type `str`:"
      ],
      "metadata": {
        "id": "qKHcjTDYLfRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = 'Messi'\n",
        "type(c)"
      ],
      "metadata": {
        "id": "4j7NhopFLiRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The quote marks indicate type `str`. You can use single or double quotes, but take care of using the same on both sides of the string. Strings come in Python with many methods attached. Some of these methods will appear later in this course, in the examples."
      ],
      "metadata": {
        "id": "1qSdmrXZLnUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lists"
      ],
      "metadata": {
        "id": "k4x1adE2LrQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python has several types for objects that work as **data containers**. The most versatile is the **list**, which is represented as a sequence of comma-separated values inside square brackets. Lists can contain items of different type. A simple example of a list, of length 4, follows."
      ],
      "metadata": {
        "id": "mnCWBbstMCph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mylist = ['Vinicius', 'Messi', 'Yamal', 'MbappÃ©']"
      ],
      "metadata": {
        "id": "2oRL2QJPMFGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(mylist)"
      ],
      "metadata": {
        "id": "VsZ0qQ8LNzwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lists can be concatenated in a very simple way in Python:"
      ],
      "metadata": {
        "id": "i_omGAUPOGfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newlist = mylist + [2, 3]\n",
        "newlist"
      ],
      "metadata": {
        "id": "TpsBBmqHOKg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the length of `newlist` is 6:"
      ],
      "metadata": {
        "id": "6Cpd_YuEOOdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(newlist)"
      ],
      "metadata": {
        "id": "dpW5jqQFOQ8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first item of `mylist` can be extracted as `mylist[0]`, the second item as `mylist[1]`, etc. The last item can be extracted either as `mylist[3]` or as `mylist[-1]`. Sublists can be extracted by using a colon inside the brackets, as in:"
      ],
      "metadata": {
        "id": "FoIlqq3hOT5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mylist[0:2]"
      ],
      "metadata": {
        "id": "VkjolkBGObJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that `0:2` includes `0` but not `2`. This is a general rule for indexing in Python. Other examples:"
      ],
      "metadata": {
        "id": "5No1tL9IOeIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mylist[2:]"
      ],
      "metadata": {
        "id": "pZ_Ge6JzOhsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mylist[:3]"
      ],
      "metadata": {
        "id": "nMgH9UAfQFOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The items of a list are ordered, and can be repeated. This is not so in other data containers."
      ],
      "metadata": {
        "id": "_nu3VCLDQJCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ranges"
      ],
      "metadata": {
        "id": "gbtHicPtQNoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **range** is a sequence of integers which in many aspects works as a list, but the terms of the sequence are not saved as in a list. Instead, only the procedure to create the sequence is saved. The syntax is `range(start, end, step)`. Example:"
      ],
      "metadata": {
        "id": "D7hmc51UQQVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myrange = range(0, 10, 2)\n",
        "list(myrange)"
      ],
      "metadata": {
        "id": "-cOTlUo6QTZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the items from a range cannot printed directly. So, we have converted the range to a list with the function `list`. If  `step` is omitted, it is assumed to be 1:"
      ],
      "metadata": {
        "id": "Wg62shFUQYG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(range(5, 12))"
      ],
      "metadata": {
        "id": "IAnOsZO-QbCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If `start` is also omitted, it is assumed to be 0:"
      ],
      "metadata": {
        "id": "JQCWcQ6kQdOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(range(10))"
      ],
      "metadata": {
        "id": "IWV4fLxvQh3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dictionaries"
      ],
      "metadata": {
        "id": "vxOGoABSQkEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **dictionary** is a set of **pairs key/value**. For instance, the following dictionary contains three features of an individual:"
      ],
      "metadata": {
        "id": "Rw8mQwySQmnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict = {'name': 'Joan', 'gender': 'F', 'age': 32}"
      ],
      "metadata": {
        "id": "vi88_itFRRng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The keys can be listed:"
      ],
      "metadata": {
        "id": "fsBdz03vRVAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict.keys()"
      ],
      "metadata": {
        "id": "i7tiPbPhRo3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dictionary, a value is not extracted using an index which indicates its order in a sequence, as in the list, but using the corresponding key:"
      ],
      "metadata": {
        "id": "LSwKJl6QRrj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict['name']"
      ],
      "metadata": {
        "id": "4IbFp2vjR2k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other data container types"
      ],
      "metadata": {
        "id": "wEGnSV6lR5Oa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The packages used in data science come with new data container types: NumPy arrays, Pandas series and Pandas data frames. Dealing with so many types of objects is a bit challenging for the beginner. The elements of the Python data containers (*e.g*. lists) can have different data types, but NumPy and Pandas data containers have consistency constraints. So, an array has a unique data type, while a data frame has a unique data type for every column."
      ],
      "metadata": {
        "id": "PwzTYjhHR-Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Functions"
      ],
      "metadata": {
        "id": "_8usRE3JSHAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **function** takes a collection of **arguments** and performs an action. Let me present a couple of examples of value-returning functions. They are easily distinguished from other functions, because the definition's last line is a `return` clause.\n",
        "\n",
        "A first example follows. Note the **indentation** after the colon, which is created automatically by the console."
      ],
      "metadata": {
        "id": "pjrCyySMSJZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    y = 1/(1 - x**2)\n",
        "    return y"
      ],
      "metadata": {
        "id": "60oR4vPqStLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we define a function, Python just takes note of the definition, accepting it when it is syntactically correct (parentheses, commas, etc). The function can be applied later to different arguments."
      ],
      "metadata": {
        "id": "xgBDmX7zTC3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f(2)"
      ],
      "metadata": {
        "id": "-50spRqRTF8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we apply the function to an argument for which it does not make sense, Python will return an error message which depends on the values supplied for the argument."
      ],
      "metadata": {
        "id": "iaHuW6BdUZLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f('Mary')"
      ],
      "metadata": {
        "id": "wryRPN7_Ufud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions can have more than one argument, as in:"
      ],
      "metadata": {
        "id": "DdKUKnbbUi_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def g(x, y): return x*y/(x**2 + y**2)\n",
        "g(1, 1)"
      ],
      "metadata": {
        "id": "8O7jDzdZUmM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that, in the definition of `g()`, I have used a shorter way. Most programmers would make it longer, as I did previously for `f()`."
      ],
      "metadata": {
        "id": "xsU1pZZbUuPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NumPy arrays"
      ],
      "metadata": {
        "id": "u28v7CYVUydH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In mathematics, a **vector** is a sequence of numbers, and a **matrix** is a rectangular arrangement of numbers. Operations with vectors and matrices are the subject of a branch of mathematics called linear algebra. In Python (and in many other languages), vectors are called one-dimensional (1D) **arrays**, while matrices are called two-dimensional (2D) arrays. Arrays of more than two dimensions can be managed in Python without pain.\n",
        "\n",
        "Python arrays are not necessarily numeric. Indeed, vectors of dates and strings appear frequently in data science. In principle, all the terms of an ordinary array must have the same type, so the array itself can have a type, though you can relax this constraint using mixed types (not covered by this course). Arrays were already implemented in plain Python, but the functionality of the Python arrays was enlarged in **NumPy**, intended to be the fundamental library for scientific computing in Python.\n",
        "\n",
        "The usual way to import NumPy is:"
      ],
      "metadata": {
        "id": "JnpKcWnhTMxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "DYUJTMorTSQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 1D array can be created from a list with the NumPy function `array()`. If the items of the list have different type, they are converted to a common type when creating the array. A simple example follows."
      ],
      "metadata": {
        "id": "iRvzeeLkTUb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr1 = np.array([2, 7, 14, 5, 9])\n",
        "arr1"
      ],
      "metadata": {
        "id": "fkyr727_TYiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 2D array can be directly created from a list of lists of equal length. The terms are entered row-by-row:"
      ],
      "metadata": {
        "id": "qYXtyrvuTg1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr2 = np.array([[0, 7, 2, 3], [3, 9, -5, 1]])\n",
        "arr2"
      ],
      "metadata": {
        "id": "nSLf1LyoTjTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although we visualize a vector as a column (or as a row) and a matrix as a rectangular arrangement, with rows and columns, it is not so in the computer. The 1D array is just a sequence of elements of the same type, neither horizontal nor vertical. It has one **axis**, which is the 0-axis.\n",
        "\n",
        "In a similar way, a 2D array is a sequence of 1D arrays of the same length and type. It has two axes. When we visualize it as rows and columns, `axis=0` means *across rows*, while `axis=1` means *across columns*.\n",
        "\n",
        "The number of terms stored along an axis is the **dimension** of that axis. The dimensions are collected in the attribute `.shape`."
      ],
      "metadata": {
        "id": "sVf4qDArToFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr1.shape"
      ],
      "metadata": {
        "id": "cm27L4IuTv29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr2.shape"
      ],
      "metadata": {
        "id": "0D0WWtOqT8FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NumPy functions"
      ],
      "metadata": {
        "id": "m1RX0UBEUAZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy incorporates vectorized forms of the **mathematical functions** of the package `math`. A **vectorized function** is one that, when applied to an array, returns an array with the same shape, whose terms are the values of the function on the corresponding terms of the original array.\n",
        "\n",
        "For instance, the square root function `np.sqrt()` takes the square root of every term of a numeric array:"
      ],
      "metadata": {
        "id": "kSlyTcsFUKQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(arr1)"
      ],
      "metadata": {
        "id": "_P7f1ABfUOAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The functions that are defined in terms of vectorized functions are automatically vectorized. For instance:"
      ],
      "metadata": {
        "id": "0ceG0rqPUQyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(t): return 1/(1 + np.exp(t))\n",
        "f(arr2)"
      ],
      "metadata": {
        "id": "bEE8jDMqUZ71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy also provides common **statistical functions**, such as `mean()`, `max()`, `sum()`, etc."
      ],
      "metadata": {
        "id": "eGKdk6UqU7z1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subsetting arrays"
      ],
      "metadata": {
        "id": "lnqxEm0ZVEWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subsetting** a 1D array is done as for a list:"
      ],
      "metadata": {
        "id": "93CD0p1PVppd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr1[:3]"
      ],
      "metadata": {
        "id": "gKva_C1YWNLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same applies to 2D arrays, but we need two indexes within the square brackets. The first index selects the rows (`axis=0`), and the second index the columns (`axis=1`):"
      ],
      "metadata": {
        "id": "XyQMvoP3WQpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr2[:1, 1:]"
      ],
      "metadata": {
        "id": "jXGQyuwaWW3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When an expression involving an array is evaluated by the Python kernel, a Boolean array with the same shape is returned:"
      ],
      "metadata": {
        "id": "XWuj5-9NWhFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr1 > 3"
      ],
      "metadata": {
        "id": "CGm9e1m-Wjvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr2 > 2"
      ],
      "metadata": {
        "id": "tK3GeYmYWs9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A subarray can be extracted by means of an expression. The expression is evaluated, returning a Boolean array called **Boolean mask**. The terms for which the mask is true are selected:"
      ],
      "metadata": {
        "id": "aCQ_KYc1Wvgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr1[arr1 > 3]"
      ],
      "metadata": {
        "id": "44-iags0WyYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this is the same as"
      ],
      "metadata": {
        "id": "wzpCFsY6W5T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr1[[False,  True,  True,  True,  True]]"
      ],
      "metadata": {
        "id": "E1LI9uKHcDsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boolean masks can also be used to filter out rows or columns of a 2d array. For instance, you can select the rows of `arr2` for which the first column is positive,"
      ],
      "metadata": {
        "id": "gt_zayeicFoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr2[arr2[:, 0] > 0, :]"
      ],
      "metadata": {
        "id": "Or1QnZMecLwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The package Pandas"
      ],
      "metadata": {
        "id": "OL_EbF5ecYA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pandas** provides a wide range of data wrangling tools. It is typically imported as"
      ],
      "metadata": {
        "id": "XRlGoGD5caYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yyXQQxHKclNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas provides two data container classes, the series (one-dimensional) and the data frames (two-dimensional). A **series** can be understood as the combination of a 1D array containing the **values** and a list containing the names of the values, called the **index**. These components can be extracted as the attributes `.values` and `.index`.\n",
        "\n",
        "A **data frame** can be seen as formed by one or several series with the same index (hence, with the same length). It can also be seen as a table for which the index provides the row names. In a Pandas data frame, each column has its own data type. The numeric types work as usual, but Pandas uses the data type `object` for many things, in particular for strings."
      ],
      "metadata": {
        "id": "4I8C9VIocyYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas series"
      ],
      "metadata": {
        "id": "OmzfVTWUc1cN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although we rarely do it in data science, where the data are imported from external data files, a Pandas series can be created directly, for instance from an array, with the Pandas function `Series()`:"
      ],
      "metadata": {
        "id": "L8A5CscKdDe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = pd.Series(arr1)\n",
        "print(s1)"
      ],
      "metadata": {
        "id": "QNJuv3ledHWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the values of the series are extracted as:"
      ],
      "metadata": {
        "id": "69uRZjNLdLxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1.values"
      ],
      "metadata": {
        "id": "ZwSHNIWtdgbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown above, when a series is printed, the index appears on the left. Since the index of `s1` has not been specified, a range of consecutive integers has been assigned as the index."
      ],
      "metadata": {
        "id": "q2-VXpFBdjKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1.index"
      ],
      "metadata": {
        "id": "Jh2INrRhf3zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of an array, a list can be used to provide the values of a series. In the list, the items can have different type, but Pandas converts them to a common type, as shown in the following example. Here, instead of letting the Python kernel to create an index automatically, as a `RangeIndex`, we specify an index directly:"
      ],
      "metadata": {
        "id": "RZih1Cxqf7EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s2 = pd.Series([1, 5, 'Messi'], index = ['a', 'b', 'c'])\n",
        "print(s2)"
      ],
      "metadata": {
        "id": "Jg0RH0rKf-CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the index is a plain `Index`:"
      ],
      "metadata": {
        "id": "ULaRBYfTgFA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s2.index"
      ],
      "metadata": {
        "id": "7c0LVCGDgQik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexes are useful for combining, filtering and joining data sets. There are many types of indexes, which allow for specific operations. So, do not look at the index as an embarrassment, which is what it seems at first sight, but as a tool for data management."
      ],
      "metadata": {
        "id": "qDOc33GhgS4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas data frames"
      ],
      "metadata": {
        "id": "KLba12gngWgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Pandas **data frame** can be seen as a collection of series with the same index (hence, with the same length). Data frames can be built in many ways with the Pandas function `DataFrame()`, for instance from a dictionary of vector-like objects of the same length, as in"
      ],
      "metadata": {
        "id": "PSLtzc-ygYxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'v1': range(5), 'v2': ['a', 'b', 'c', 'd', 'e'], 'v3': np.repeat(-1.3, 5)})\n",
        "print(df)"
      ],
      "metadata": {
        "id": "PqTEb-FPgero"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the series, the data frames have the attributes `.values` and `.index`:"
      ],
      "metadata": {
        "id": "hT3kSePygzF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.values"
      ],
      "metadata": {
        "id": "4hRLK76Bg2nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df.index"
      ],
      "metadata": {
        "id": "i55xmNCzg4zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without a explicit specification, the index is automatically created as a `RangeIndex`. In this example, since the columns have different data types, `df.values` takes type `object`. The third component of the data frame is a list with the column names, which can be extracted as the attribute `.columns`:"
      ],
      "metadata": {
        "id": "z25Yr2qHg7fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "r9ulWnsIhKqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A data frame has the same shape of the array of values. Having rows and columns, a data frame looks like a 2D array with row and column names. Indeed, we can also create data frames in this way:"
      ],
      "metadata": {
        "id": "wUfp6kqKhNhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame(arr2))"
      ],
      "metadata": {
        "id": "vdPbqg_ehQpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But not all data frames are so simple. While a NumPy 2D array has a data type, in a Pandas data frame every column has its own data type.\n",
        "\n",
        "Data frames can also be extracted from a data source (local or remote), such as a CSV file, an Excel sheet, or a table from a relational database. As for the series, a range index is automatically created unless an alternative specification is provided. The same is true for column names, so, in the above example, `df.columns` returns a range of integers. It is recommended to choose a column name which suggests the content of the column."
      ],
      "metadata": {
        "id": "agR8f2bohT-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Pandas objects"
      ],
      "metadata": {
        "id": "hh2bDzhlhXow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The methods `.head()` and `.tail()` extract the first and the last rows of a data frame, respectively. The default number of rows extracted is 5, but you can pass a custom number."
      ],
      "metadata": {
        "id": "70wWR0a0ja8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(2))"
      ],
      "metadata": {
        "id": "LGiWvmdgjdP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The content of a data frame can also be explored with the method `.info()`. It reports the dimensions, the data type and the number of non-missing values of every column of the data frame. Note that the data type of the second column, for which you would have expected `str`, is reported as `object`. Don't worry about this, you can apply the string methods to this column, as will be seen later in this course."
      ],
      "metadata": {
        "id": "5lqF4ubAjf2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "n-Jcl9qtjjBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method `.describe()` extracts a conventional statistical summary of a Pandas object. The columns of type `object` are omitted, except when all the columns have that type. Then the report contains only counts."
      ],
      "metadata": {
        "id": "BcGZkSipjsgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe())"
      ],
      "metadata": {
        "id": "jw7FNCeXjvI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subsetting data frames"
      ],
      "metadata": {
        "id": "wVZLESBGjyqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas offers multiple ways for subsetting data frames. First, you can extract a column, as a series:"
      ],
      "metadata": {
        "id": "v1EvOxjjj5oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['v2'])"
      ],
      "metadata": {
        "id": "fXUk9mo8j7p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the syntax is the same as for extracting the value of a key from a dictionary (not by chance). You can also extract a **data subaframe** containing a subset of complete columns from a data frame. You can specify this with a list containing the names of those columns:"
      ],
      "metadata": {
        "id": "lAtkST6Ej-wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['v1', 'v2']])"
      ],
      "metadata": {
        "id": "y4bKPDVskE52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note*. You can extract a subframe with a single column. Beware that this is not the same as a series. `df['v2']`is a series with shape `(5,)`, and `df[['v2']]` is a data frame with shape `(5,1)`.\n",
        "\n",
        "In data science, rows are typically filtered by expressions. Example:"
      ],
      "metadata": {
        "id": "NpIbdfMhkIEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[df['v1'] > 2])"
      ],
      "metadata": {
        "id": "7viNenqDkLby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining a row filter and a column selection:"
      ],
      "metadata": {
        "id": "reKNyjmPkOY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[df['v1'] > 2][['v1', 'v2']])"
      ],
      "metadata": {
        "id": "j6S4m7CakRYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Besides this, there are two additional ways to carry out a selection, specifying rows and columns in one shot:\n",
        "\n",
        "* **Selection by label** is specified by adding  `.loc` after the name of the data frame. The selection of the rows is based on the index, and that of the columns is based on the column names.\n",
        "\n",
        "* **Selection by position** uses `.iloc`. The selection of the rows is based on the row number and that of the columns on the column number.\n",
        "\n",
        "In both cases, if you enter a single specification inside the brackets, it refers to the rows. If you enter two specifications, the first one refers to the rows and the second one to the columns. We don't use `loc` and `iloc` in this course, since you can live in Pandas without that, selecting first the rows and then the columns. Sticking to this simple approach, you will save the time wasted learning too many methods."
      ],
      "metadata": {
        "id": "X2XpGf5LkUa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing data from CSV files"
      ],
      "metadata": {
        "id": "NtFqUFM0vM1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data sets in tabular form can be imported as Pandas data frames from many file formats. In particular, data from a CSV file can be imported to a data frame with the Pandas function `read_csv`(). The (default) syntax is `dfname = pd.read_csv(fname)`. The data frame name is chosen by the user, and the file name has to contain the **path** of that file (either local or remote). `read_csv()` works the same way for CSV files and for **zipped ZIP files**.\n",
        "\n",
        "Although defaults work in most cases satisfactorily, it is worth to comment a few things about some optional arguments of `read_csv()`. The list is not complete, but enough to give you an idea of the extent to which you can customize this function.\n",
        "\n",
        "* The parameter `sep` specifies the column separator. The default is `sep=','`, but CSV files created with Excel may need `sep=';'`.\n",
        "\n",
        "* The parameters `header` and `names` specify the row where the data to be imported start and the column names, respectively. The default is `header=0, names=None`, which makes Pandas start reading from the first row and take it as the column names. When the data come without names, you can use `header=None, names=namelist` to provide a list of names. With a positive value for `header`, you can skip some rows.\n",
        "\n",
        "* The parameter `index_col` specifies a column that you wish to use as the index, if that is the case. The default is `index_col=None`. If the intended index comes in the first column, as it frequently happens, you will use `index_col=0`.\n",
        "\n",
        "* The parameter `usecols` specifies the columns to be read. You can specify them in a list, either by name or by position. The default is `usecols=None`, which means that you wish to read all the columns.\n",
        "\n",
        "* The parameter `dtype` specifies the data types of the columns of the data frame. This saves time with big data sets. The default is `dtype=None`, which means that Python will guess the data type, based on what it reads. When all the entries in a column are numbers, that column is imported as numeric. If there is, at least, one entry that is not numeric, all the entries are read as strings, and the data type `object` is assigned to that column.\n",
        "\n",
        "* If the string data contained in a CSV file can contain special characters (such as Ã±, or Ã¡), which can make trouble, you may need to control the parameter `encoding`. The default is `encoding='utf-8'`. So, if you are reading a CSV file created in Excel, you may need to set `encoding='latin'` to read the special characters in the right way."
      ],
      "metadata": {
        "id": "c3bWS_TlvPcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary statistics"
      ],
      "metadata": {
        "id": "s-65KSVMvTxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method `.describe()` extracts a conventional statistical summary. Columns of type `object` are omitted, except when all the columns have that type. Then the report contains just counts.\n",
        "\n",
        "Basic statistics can also be calculated separately. For instance, the method `.mean()` returns the column means of a data frame. Correlations are also pretty easy:\n",
        "\n",
        "* For a pair of series, `s1` and `s2`, `s1.corr(s2)` returns the **correlation** of `s1` and `s2`.\n",
        "\n",
        "* For a data frame `df`, `df.corr()` returns the **correlation matrix** for the columns of `df`."
      ],
      "metadata": {
        "id": "GP_WmOTN0IzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting"
      ],
      "metadata": {
        "id": "_OeUgShk7H-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We typically visualize the data with bar plots, histograms, scatter plots and line plots. They can be obtained directly from a Pandas object. Suppose first that `df` is a Pandas data frame and set `cname1` as the *x*-column and `cname2` as the *y*-column (numeric). To explore the dependence of the *y*-column on the *x*-column, we use a **bar plot**, when the *x*-column is categorical, and a **scatter plot**, when it is numeric:\n",
        "\n",
        "* `df.plot.bar(x=cname1, y=cname2)` returns a bar plot. The bars represent the values of the column `cname2` for the different values of the column `cname1`. If you do not specify the *x*-column, the index is used instead.\n",
        "\n",
        "* `df.plot.scatter(x=cname1, y=cname2)` returns a scatter plot.\n",
        "\n",
        "Suppose now that `s` is a numeric Pandas series. To explore the distribution of `s`, you use a **histogram**. Alternatively, to explore a trend, you use a **line plot**. This is pretty easy in Pandas:\n",
        "\n",
        "* `s.plot.hist()` returns a histogram.\n",
        "\n",
        "* `s.plot.line()` returns a line plot.\n",
        "\n",
        "Pandas uses Matplotlib functions, but not explicitly. If you are satisfied with a basic functionality, you can skip Matplotlib in your code.\n"
      ],
      "metadata": {
        "id": "MIlJICsU7KrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorting"
      ],
      "metadata": {
        "id": "upyYQ4F47q6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two **sorting** methods in Pandas. A series can be sorted by the index or by the values, with the methods `.sort_index()` and `.sort_values()`, respectively. Both methods work for data frames, but, for the second one, you have to specify either the name of a column or a list of column names, which will then be used in the order that you wrote them.\n",
        "\n",
        "The parameter `ascending` allows you to choose between ascending and descending ways. The default is `ascending=True`."
      ],
      "metadata": {
        "id": "0HaNCMzf78Fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing values"
      ],
      "metadata": {
        "id": "eWl9VXQo-neX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing values** are denoted by `NaN` in Pandas. When a Pandas object is built, both Python's `None` and NumPy's `nan` are taken as `NaN`. Since `np.nan` has type `float`, numeric columns containing `NaN` values get type `float`.\n",
        "\n",
        "Three useful Pandas methods related to missing values, which can be applied to both series and data frames, are:\n",
        "\n",
        "* `.isna()` returns a Boolean Pandas object of the same shape, indicating which terms are missing.\n",
        "\n",
        "* `.fillna(value)` fills missing values.\n",
        "\n",
        "* `.dropna()` removes the rows that contain at least one missing value."
      ],
      "metadata": {
        "id": "j11id_mc-pyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Duplicates"
      ],
      "metadata": {
        "id": "QDoXdLpW-5nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two useful Pandas methods for managing **duplicates**:\n",
        "\n",
        "* `.duplicated()` returns a Boolean series indicating the rows that are duplicated. The default of this method performs a top-down check of the data, returning `False` for the values occurring for the first time, and `True` for those having occurred before. You can reverse this with the argument `keep=last`.\n",
        "\n",
        "* `.drop_duplicates()` drops the duplicated rows. It is based on the Boolean mask created by `.duplicated()`."
      ],
      "metadata": {
        "id": "7As1fXyLA0dV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grouping and aggregation"
      ],
      "metadata": {
        "id": "7mPtGZMvA3og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When exploring data, we often use tables for discovering patterns. They can be produced in various ways in Pandas:\n",
        "\n",
        "* The method `.value_counts()` extracts a **frequency table**. The table contains the counts of the occurrences of every value of a given series. It does not include the missing values.\n",
        "\n",
        "* The function `crosstab()` extracts a **cross tabulation**. For two series of the same length `s1` and `s2`, the syntax is `pd.crosstab(s1, s2)`. Then `s1` will be placed on the rows and `s2` on the columns. By default, `crosstab()` extracts a frequency table, unless an array of values (parameter `values`) and an **aggregate function** (parameter `aggfunc`) are passed.\n",
        "\n",
        "* The function `pivot_table()` extracts a **spreadsheet-style pivot table**. For a Pandas data frame `df`, the syntax is `pd.pivot_table(df, values=col1, index=col2)`. This returns a **one-way table** containing the average value of the column `col1` for the groups defined by the column `col2`. Instead of the average, you can get a different summary by adding an argument `aggfunc=[f1, f2, ...]`. With an additional argument `columns=col3`, you get a **two-way table**. For two-way tables, this function works the same as `crosstab()`, but it can only be applied to columns from the same data frame.\n",
        "\n",
        "* The method `.groupby()` groups the rows of a data frame so that an aggregate function can be applied to every group, extracting a **SQL-like table** as a data frame. The syntax is `df.groupby(by=col).f()`. To apply more than one function, use `df.groupby(by=col).agg([f1, f2, ...])`."
      ],
      "metadata": {
        "id": "dnznBn5rA6za"
      }
    }
  ]
}